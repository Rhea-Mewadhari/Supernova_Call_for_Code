# -*- coding: utf-8 -*-
"""CIDnet_low_light enchancement.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jPNbXhzF7vK_p89VpDBTaay-FhDuA-uB
"""

import zipfile
import os
from collections import defaultdict
zip_file_path = './noise.zip'

extract_dir = './'

os.makedirs(extract_dir, exist_ok=True)

with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_dir)

print("Extraction complete.")

import tensorflow as tf
import keras

print("TensorFlow version:", tf.__version__)
print("Keras version:", keras.__version__)

import cv2
import os

def resize_images(input_folder, output_folder, target_size):
    # Create output folder if it doesn't exist
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # Iterate through images in the input folder
    for filename in os.listdir(input_folder):
        if filename.endswith(".jpg") or filename.endswith(".png"):
            # Read image
            img = cv2.imread(os.path.join(input_folder, filename))

            # Resize image to target size (224x224)
            resized_img = cv2.resize(img, target_size)

            # Save resized image to output folder
            output_path = os.path.join(output_folder, filename)
            cv2.imwrite(output_path, resized_img)

# Example usage
input_folder = "./noise"
output_folder = "./resize"
target_size = (224, 224)

resize_images(input_folder, output_folder, target_size)

import os
import numpy as np
import cv2

def darken_image(input_image_path, output_image_path, intensity_range=(0.3, 0.5)):

    image = cv2.imread(input_image_path)

    intensity_factor = np.random.uniform(*intensity_range)

    darkened_image = np.clip(image * intensity_factor, 0, 255).astype(np.uint8)

    cv2.imwrite(output_image_path, darkened_image)

input_image_path = 'input_image.jpg'
output_image_path = 'output_image.jpg'

darken_image(input_image_path, output_image_path)

import cv2
import numpy as np
import os

def simulate_low_light_dataset(input_folder, output_folder, intensity_range=(0.3, 0.5)):
    # Create output folder if it doesn't exist
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # Iterate through images in the input folder
    for filename in os.listdir(input_folder):
        if filename.endswith(".jpg") or filename.endswith(".png"):
            # Read image
            image_path = os.path.join(input_folder, filename)
            image = cv2.imread(image_path)

            # Generate a random intensity factor within the specified range
            intensity_factor = np.random.uniform(*intensity_range)

            # Adjust the intensity
            darkened_image = np.clip(image * intensity_factor, 0, 255).astype(np.uint8)

            # Save darkened image to output folder with the same filename
            output_path = os.path.join(output_folder, filename)
            cv2.imwrite(output_path, darkened_image)

            # Optionally display the original and darkened images
            # cv2.imshow("Original Image", image)
            # cv2.imshow("Darkened Image", darkened_image)
            # cv2.waitKey(0)
            # cv2.destroyAllWindows()

# Example usage
input_folder = "./resize"
output_folder = "./low"
intensity_range = (0.1, 0.3)  # Adjusted to retain 50% to 80% of initial intensity

simulate_low_light_dataset(input_folder, output_folder, intensity_range)

!export XLA_PYTHON_CLIENT_MEM_FRACTION=2.0

import os
import cv2
import numpy as np
import tensorflow as tf
import joblib
from tensorflow.keras import layers, models

# Define CIDNet architecture for color images
def CIDNet(input_shape):
    inputs = layers.Input(shape=input_shape)

    # Encoder
    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)
    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)

    # Decoder
    conv2 = layers.Conv2D(64, 3, activation='relu', padding='same')(pool1)
    up1 = layers.UpSampling2D(size=(2, 2))(conv2)
    conv3 = layers.Conv2D(3, 3, activation='sigmoid', padding='same', name='conv3')(up1)  # Output has 3 channels for color images

    model = models.Model(inputs=inputs, outputs=conv3)
    return model

# Load color images
def load_dataset(well_lit_dir, low_lit_dir):
    well_lit_images = []
    low_lit_images = []

    for filename in os.listdir(well_lit_dir):
        img = cv2.imread(os.path.join(well_lit_dir, filename))
        if img is not None:
            well_lit_images.append(img)

    for filename in os.listdir(low_lit_dir):
        img = cv2.imread(os.path.join(low_lit_dir, filename))
        if img is not None:
            low_lit_images.append(img)

    return np.array(well_lit_images), np.array(low_lit_images)

# Normalize color images
def normalize_images(images):
    return images.astype('float32') / 255.0

# Define custom loss functions
def color_constancy_loss(y_true, y_pred):
    mean_rgb = tf.reduce_mean(y_pred, axis=(1, 2), keepdims=True)
    mr, mg, mb = mean_rgb[:, :, :, 0], mean_rgb[:, :, :, 1], mean_rgb[:, :, :, 2]
    d_rg = tf.square(mr - mg)
    d_rb = tf.square(mr - mb)
    d_gb = tf.square(mb - mg)
    return tf.sqrt(tf.square(d_rg) + tf.square(d_rb) + tf.square(d_gb))

def exposure_loss(y_true, y_pred):
    y_pred = tf.reduce_mean(y_pred, axis=3, keepdims=True)
    mean = tf.nn.avg_pool2d(y_pred, ksize=16, strides=16, padding="VALID")
    return tf.reduce_mean(tf.square(mean - 0.6))

def illumination_smoothness_loss(y_true, y_pred):
    batch_size = tf.shape(y_pred)[0]
    h_x = tf.shape(y_pred)[1]
    w_x = tf.shape(y_pred)[2]
    count_h = (tf.shape(y_pred)[1] - 1) * tf.shape(y_pred)[3]
    count_w = tf.shape(y_pred)[2] * (tf.shape(y_pred)[3] - 1)
    h_tv = tf.reduce_sum(tf.square((y_pred[:, 1:, :, :] - y_pred[:, : h_x - 1, :, :])))
    w_tv = tf.reduce_sum(tf.square((y_pred[:, :, 1:, :] - y_pred[:, :, : w_x - 1, :])))
    batch_size = tf.cast(batch_size, dtype=tf.float32)
    count_h = tf.cast(count_h, dtype=tf.float32)
    count_w = tf.cast(count_w, dtype=tf.float32)
    return 2 * (h_tv / count_h + w_tv / count_w) / batch_size

# Main function for training CIDNet
def train_CIDNet(well_lit_images, low_lit_images):
    input_shape = well_lit_images[0].shape  # Input shape without channel dimension
    model = CIDNet(input_shape)

    # Compile the model with custom loss functions
    model.compile(optimizer='adam', loss={'conv3': 'mean_squared_error'},
                  loss_weights={'conv3': 1.0},
                  metrics=[color_constancy_loss, exposure_loss, illumination_smoothness_loss])

    # Train the model
    model.fit(low_lit_images, {'conv3': well_lit_images}, epochs=30, batch_size=32, shuffle=True)

    return model

def main():
    # Define paths
    well_lit_directory = "./resize"
    low_lit_directory = "./low"

    # Load dataset
    well_lit_images, low_lit_images = load_dataset(well_lit_directory, low_lit_directory)

    # Normalize images
    normalized_well_lit_images = normalize_images(well_lit_images)
    normalized_low_lit_images = normalize_images(low_lit_images)

    # Train CIDNet model
    trained_model = train_CIDNet(normalized_well_lit_images, normalized_low_lit_images)

    # Save the entire trained model using joblib
    joblib.dump(trained_model, 'CIDNet_model.joblib')

if __name__ == "__main__":
    main()

!pip install gradio

import os
import cv2
import numpy as np
import tensorflow as tf
import joblib
import gradio as gr

from tensorflow.keras import backend as K
from tensorflow.keras.utils import register_keras_serializable

@register_keras_serializable(package='CustomLosses')
def color_constancy_loss(y_true, y_pred):
    mean_rgb = K.mean(y_pred, axis=(1, 2), keepdims=True)
    mr, mg, mb = mean_rgb[:, :, :, 0], mean_rgb[:, :, :, 1], mean_rgb[:, :, :, 2]
    d_rg = K.square(mr - mg)
    d_rb = K.square(mr - mb)
    d_gb = K.square(mb - mg)
    return K.sqrt(K.square(d_rg) + K.square(d_rb) + K.square(d_gb))


@register_keras_serializable(package='CustomLosses')
def exposure_loss(y_true, y_pred):
    y_pred = K.mean(y_pred, axis=3, keepdims=True)
    mean = K.mean(K.pool2d(y_pred, pool_size=(16, 16), strides=(16, 16), padding="VALID"))
    return K.mean(K.square(mean - 0.6))

@register_keras_serializable(package='CustomLosses')
def illumination_smoothness_loss(y_true, y_pred):
    batch_size = K.cast(K.shape(y_pred)[0], dtype=K.floatx())
    h_x = K.cast(K.shape(y_pred)[1], dtype=K.floatx())
    w_x = K.cast(K.shape(y_pred)[2], dtype=K.floatx())
    count_h = (K.shape(y_pred)[2] - 1) * K.shape(y_pred)[3]
    count_w = K.shape(y_pred)[2] * (K.shape(y_pred)[3] - 1)
    h_tv = K.sum(K.square((y_pred[:, 1:, :, :] - y_pred[:, : K.cast(h_x - 1, dtype=K.int32), :, :])))
    w_tv = K.sum(K.square((y_pred[:, :, 1:, :] - y_pred[:, :, : K.cast(w_x - 1, dtype=K.int32), :])))
    return 2 * (h_tv / count_h + w_tv / count_w) / batch_size

# Normalize and load a single image
def load_and_normalize_image(image):
    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    img = img.astype('float32') / 255.0
    img = np.expand_dims(img, axis=0)  # Add batch dimension
    return img

# Load the saved model with joblib
def load_model():
    model = joblib.load('CIDNet_model.joblib')
    model.compile(optimizer='adam', loss={'conv3': 'mean_squared_error'},
                  loss_weights={'conv3': 1.0},
                  metrics=[color_constancy_loss, exposure_loss, illumination_smoothness_loss])
    return model

# Function to process the image using the CIDNet model
def process_image(image):
    model = load_model()
    normalized_image = load_and_normalize_image(image)

    if normalized_image is not None:
        # Predict the output for the new image
        output_image = model.predict(normalized_image)

        # Convert the output image from normalized form back to 8-bit form
        output_image = (output_image[0] * 255).astype(np.uint8)

        # Convert from RGB to BGR for display in Gradio
        output_image = cv2.cvtColor(output_image, cv2.COLOR_RGB2BGR)

        return output_image
    else:
        return None

# Define the Gradio interface
iface = gr.Interface(
    fn=process_image,
    inputs=gr.Image(type="numpy"),
    outputs=gr.Image(type="numpy"),
    description="Upload a low-lit image to enhance it using CIDNet."
)

# Launch the Gradio interface
if __name__ == "__main__":
    iface.launch(debug=True)

from tensorflow.keras import layers, models
from tensorflow.keras.saving import register_keras_serializable

@register_keras_serializable()
def CIDNet(input_shape):
    inputs = layers.Input(shape=input_shape)

    # Encoder
    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)
    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)

    # Decoder
    conv2 = layers.Conv2D(64, 3, activation='relu', padding='same')(pool1)
    up1 = layers.UpSampling2D(size=(2, 2))(conv2)
    conv3 = layers.Conv2D(3, 3, activation='sigmoid', padding='same', name='conv3')(up1)  # Output has 3 channels for color images

    model = models.Model(inputs=inputs, outputs=conv3)
    return model

# Example of saving the model
input_shape = (224, 224, 3)
model = CIDNet(input_shape)
model.save_weights('cidnet.weights.h5')

with open('CIDNet_model_architecture.json', 'w') as json_file:
    json_file.write(model.to_json())

import os
import numpy as np
import cv2

def darken_image(input_image_path, output_image_path, intensity_range=(0.1,0.1)):


    image = cv2.imread(input_image_path)

    intensity_factor = np.random.uniform(*intensity_range)

    darkened_image = np.clip(image * intensity_factor, 0, 255).astype(np.uint8)

    cv2.imwrite(output_image_path, darkened_image)


input_image_path = './download (8).png'
output_image_path = 'output_image.jpg'

darken_image(input_image_path, output_image_path)

import os
import cv2
import numpy as np
import tensorflow as tf
import pickle
from tensorflow.keras import layers, models

# Define CIDNet architecture for color images
def CIDNet(input_shape):
    inputs = layers.Input(shape=input_shape)

    # Encoder
    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)
    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)

    # Decoder
    conv2 = layers.Conv2D(64, 3, activation='relu', padding='same')(pool1)
    up1 = layers.UpSampling2D(size=(2, 2))(conv2)
    conv3 = layers.Conv2D(3, 3, activation='sigmoid', padding='same', name='conv3')(up1)  # Output has 3 channels for color images

    model = models.Model(inputs=inputs, outputs=conv3)
    return model

# Load color images
def load_dataset(well_lit_dir, low_lit_dir):
    well_lit_images = []
    low_lit_images = []

    for filename in os.listdir(well_lit_dir):
        img = cv2.imread(os.path.join(well_lit_dir, filename))
        if img is not None:
            well_lit_images.append(img)

    for filename in os.listdir(low_lit_dir):
        img = cv2.imread(os.path.join(low_lit_dir, filename))
        if img is not None:
            low_lit_images.append(img)

    return np.array(well_lit_images), np.array(low_lit_images)

# Normalize color images
def normalize_images(images):
    return images.astype('float32') / 255.0

# Load and normalize a single image
def load_and_normalize_image(image_path):
    img = cv2.imread(image_path)
    if img is not None:
        img = img.astype('float32') / 255.0
        img = np.expand_dims(img, axis=0)  # Add batch dimension
    return img

# Define custom loss functions
def color_constancy_loss(y_true, y_pred):
    mean_rgb = tf.reduce_mean(y_pred, axis=(1, 2), keepdims=True)
    mr, mg, mb = mean_rgb[:, :, :, 0], mean_rgb[:, :, :, 1], mean_rgb[:, :, :, 2]
    d_rg = tf.square(mr - mg)
    d_rb = tf.square(mr - mb)
    d_gb = tf.square(mb - mg)
    return tf.sqrt(tf.square(d_rg) + tf.square(d_rb) + tf.square(d_gb))

def exposure_loss(y_true, y_pred):
    y_pred = tf.reduce_mean(y_pred, axis=3, keepdims=True)
    mean = tf.nn.avg_pool2d(y_pred, ksize=16, strides=16, padding="VALID")
    return tf.reduce_mean(tf.square(mean - 0.6))

def illumination_smoothness_loss(y_true, y_pred):
    batch_size = tf.shape(y_pred)[0]
    h_x = tf.shape(y_pred)[1]
    w_x = tf.shape(y_pred)[2]
    count_h = (tf.shape(y_pred)[2] - 1) * tf.shape(y_pred)[3]
    count_w = tf.shape(y_pred)[2] * (tf.shape(y_pred)[3] - 1)
    h_tv = tf.reduce_sum(tf.square((y_pred[:, 1:, :, :] - y_pred[:, : h_x - 1, :, :])))
    w_tv = tf.reduce_sum(tf.square((y_pred[:, :, 1:, :] - y_pred[:, :, : w_x - 1, :])))
    batch_size = tf.cast(batch_size, dtype=tf.float32)
    count_h = tf.cast(count_h, dtype=tf.float32)
    count_w = tf.cast(count_w, dtype=tf.float32)
    return 2 * (h_tv / count_h + w_tv / count_w) / batch_size

# Load the saved model
def load_model():
    # Load model architecture
    with open('CIDNet_model_architecture.json', 'r') as json_file:
        model_json = json_file.read()
    model = tf.keras.models.model_from_json(model_json)

    # Load weights
    model.load_weights('cidnet.weights.h5')

    # Compile the model with custom loss functions
    model.compile(optimizer='adam', loss={'conv3': 'mean_squared_error'},
                  loss_weights={'conv3': 1.0},
                  metrics=[color_constancy_loss, exposure_loss, illumination_smoothness_loss])

    return model

def main():
    # Load the model
    model = load_model()

    # Define the path to the new image
    new_image_path = "./output_image.jpg"

    # Load and normalize the new image
    new_image = load_and_normalize_image(new_image_path)

    if new_image is not None:
        # Predict the output for the new image
        output_image = model.predict(new_image)

        # Convert the output image from normalized form back to 8-bit form
        output_image = (output_image[0] * 255).astype(np.uint8)

        # Save the output image
        output_image_path = "./output.jpg"
        cv2.imwrite(output_image_path, output_image)
        print(f"Output image saved to {output_image_path}")
    else:
        print("Failed to load and normalize the new image.")

if __name__ == "__main__":
    main()

import cv2
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
def color_constancy_loss(y_true, y_pred):
    mean_rgb = tf.reduce_mean(y_pred, axis=(1, 2), keepdims=True)
    mr, mg, mb = mean_rgb[:, :, :, 0], mean_rgb[:, :, :, 1], mean_rgb[:, :, :, 2]
    d_rg = tf.square(mr - mg)
    d_rb = tf.square(mr - mb)
    d_gb = tf.square(mb - mg)
    return tf.sqrt(tf.square(d_rg) + tf.square(d_rb) + tf.square(d_gb))

def exposure_loss(y_true, y_pred):
    y_pred = tf.reduce_mean(y_pred, axis=3, keepdims=True)
    mean = tf.nn.avg_pool2d(y_pred, ksize=16, strides=16, padding="VALID")
    return tf.reduce_mean(tf.square(mean - 0.6))

def illumination_smoothness_loss(y_true, y_pred):
    batch_size = tf.shape(y_pred)[0]
    h_x = tf.shape(y_pred)[1]
    w_x = tf.shape(y_pred)[2]
    count_h = (tf.shape(y_pred)[2] - 1) * tf.shape(y_pred)[3]
    count_w = tf.shape(y_pred)[2] * (tf.shape(y_pred)[3] - 1)
    h_tv = tf.reduce_sum(tf.square((y_pred[:, 1:, :, :] - y_pred[:, : h_x - 1, :, :])))
    w_tv = tf.reduce_sum(tf.square((y_pred[:, :, 1:, :] - y_pred[:, :, : w_x - 1, :])))
    batch_size = tf.cast(batch_size, dtype=tf.float32)
    count_h = tf.cast(count_h, dtype=tf.float32)
    count_w = tf.cast(count_w, dtype=tf.float32)
    return 2 * (h_tv / count_h + w_tv / count_w) / batch_size
# Load the entire model using pickle
def load_entire_model_with_pickle(file_path):
    with open(file_path, 'rb') as f:
        model = pickle.load(f)
    return model

# Preprocess the image
def preprocess_image(image_path):
    # Load the image
    image = cv2.imread(image_path)
    # Resize the image to match the input shape expected by the model
    resized_image = cv2.resize(image, (input_shape[1], input_shape[0]))
    # Normalize the image
    normalized_image = resized_image.astype('float32') / 255.0
    # Expand dimensions to match the input shape expected by the model
    preprocessed_image = np.expand_dims(normalized_image, axis=0)
    return preprocessed_image

if __name__ == "__main__":
    # Load the entire model using pickle
    model_path = "CIDNet_model.pkl"
    loaded_model = load_entire_model_with_pickle(model_path, custom_objects={'color_constancy_loss': color_constancy_loss})

    # Path to the image you want to apply the model on
    image_path = "./downloadlow.png"

    # Preprocess the image
    preprocessed_image = preprocess_image(image_path)

    # Perform inference
    output_image = loaded_model.predict(preprocessed_image)

    # Display the original and output image
    original_image = cv2.imread(image_path)
    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)
    output_image = np.squeeze(output_image, axis=0)
    output_image = np.clip(output_image, 0, 1)  # Clip values to ensure they are in the valid range [0, 1]
    output_image = cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB)

    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.imshow(original_image)
    plt.title('Original Image')
    plt.axis('off')

    plt.subplot(1, 2, 2)
    plt.imshow(output_image)
    plt.title('Output Image')
    plt.axis('off')

    plt.show()

import cv2
import numpy as np
from google.colab.patches import cv2_imshow
import tensorflow as tf
import pickle

# Define custom loss functions
def color_constancy_loss(y_true, y_pred):
    mean_rgb = tf.reduce_mean(y_pred, axis=(1, 2), keepdims=True)
    mr, mg, mb = mean_rgb[:, :, :, 0], mean_rgb[:, :, :, 1], mean_rgb[:, :, :, 2]
    d_rg = tf.square(mr - mg)
    d_rb = tf.square(mr - mb)
    d_gb = tf.square(mb - mg)
    return tf.sqrt(tf.square(d_rg) + tf.square(d_rb) + tf.square(d_gb))

def exposure_loss(y_true, y_pred):
    y_pred = tf.reduce_mean(y_pred, axis=3, keepdims=True)
    mean = tf.nn.avg_pool2d(y_pred, ksize=16, strides=16, padding="VALID")
    return tf.reduce_mean(tf.square(mean - 0.6))

def illumination_smoothness_loss(y_true, y_pred):
    batch_size = tf.shape(y_pred)[0]
    h_x = tf.shape(y_pred)[1]
    w_x = tf.shape(y_pred)[2]
    count_h = (tf.shape(y_pred)[2] - 1) * tf.shape(y_pred)[3]
    count_w = tf.shape(y_pred)[2] * (tf.shape(y_pred)[3] - 1)
    h_tv = tf.reduce_sum(tf.square((y_pred[:, 1:, :, :] - y_pred[:, : h_x - 1, :, :])))
    w_tv = tf.reduce_sum(tf.square((y_pred[:, :, 1:, :] - y_pred[:, :, : w_x - 1, :])))
    batch_size = tf.cast(batch_size, dtype=tf.float32)
    count_h = tf.cast(count_h, dtype=tf.float32)
    count_w = tf.cast(count_w, dtype=tf.float32)
    return 2 * (h_tv / count_h + w_tv / count_w) / batch_size

# Load the model from the pickle file
with open('CIDNet_model.pkl', 'rb') as f:
    model = pickle.load(f)

def resize_and_preprocess_image(image_path, target_size=(224, 224)):
    image = cv2.imread(image_path) / 255.0
    resized_image = cv2.resize(image, target_size)
    return resized_image

def enhance_darkened_image(image_path, target_size=(224, 224)):
    darkened_image = resize_and_preprocess_image(image_path, target_size)

    cv2_imshow((darkened_image * 255).astype(np.uint8))

    enhanced_image = model.predict(np.expand_dims(darkened_image, axis=0))

    enhanced_image_uint8 = np.clip(enhanced_image[0] * 255, 0, 255).astype(np.uint8)

    cv2_imshow(enhanced_image_uint8)

    return enhanced_image_uint8

darkened_image_path = '/content/download (7).png'

enhanced_image = enhance_darkened_image(darkened_image_path)

import cv2
import numpy as np
from google.colab.patches import cv2_imshow
from tensorflow.keras.models import load_model


model = load_model('./CIDNet_model (1).keras')

def enhance_darkened_image(image_path):

    darkened_image = cv2.imread(image_path) / 255.0


    cv2_imshow((darkened_image * 255).astype(np.uint8))


    enhanced_image = model.predict(np.expand_dims(darkened_image, axis=0))


    enhanced_image_uint8 = np.clip(enhanced_image[0] * 255, 0, 255).astype(np.uint8)


    cv2_imshow(enhanced_image_uint8)

    return enhanced_image_uint8


darkened_image_path = '/content/darkened_image.png'


enhanced_image = enhance_darkened_image(darkened_image_path)

import os

# Print the value of image_path
print("Image path:", image_path)

# Check if the image file exists
if not os.path.isfile(image_path):
    print("Error: Image file does not exist.")
else:
    # Attempt to read the image
    image = cv2.imread(image_path)
    if image is None:
        print("Error: Failed to read the image file.")
    else:
        print("Image loaded successfully.")